# Default values for ksml.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# -- Define the k8s-resource selected to deploy the KSML Runner.
deploymentMode: StatefulSet

replicaCount: 1

# -- Job deployment specific settings.
job:
  # -- Clean up a completed or failed job after 3 days. This allows for KSML inspection after completion.
  ttlSecondsAfterFinished: 259200
  # -- Allows custom finalizers to be set on the job resource.
  finalizers: []
  # -- pod specific configurations.
  pod:
    # -- Allows custom finalizers to be set on the pod created by the job.
    finalizers: []

image:
  # -- Registry to pull the image from and the name of the image.
  repository: registry.axual.io/opensource/images/axual/ksml
  # -- One of `Always`, `IfNotPresent`, or `Never`.
  pullPolicy: IfNotPresent
  # -- Override the image tag whose default is the chart `appVersion`.
  tag: ""

# -- Override the list of ImagePullSecrets provided.
imagePullSecrets: []
# -- Override the app name generated by the chart.
nameOverride: ""
# -- Override the fully qualified app name generated by the chart.
fullnameOverride: ""

# -- KSML runner configuration. See https://axual.github.io/ksml/runners.html
ksmlRunnerConfig:
  # -- Directory containing KSML Definition files. This should only be changed if an external volume mount is used.
  definitionDirectory: '/ksml'
  # -- Directory containing the Schema files. This should only be changed if an external volume mount is used.
  schemaDirectory: '/ksml'
  # -- Directory containing the stateful data. This should only be changed if an external volume mount is used.
  storageDirectory: '/ksml-store/data'
  # -- Create the storageDirectory if it does not exist.
  createStorageDirectory: true

  # -- KSML Error handling settings. Error Handling can be defined for consume, produce and processing errors.
  errorHandling:
    # -- Error handling settings for consume related errors.
    consume:
      # -- log a message when consume errors occur.
      log: true
      # -- Add the record payload to the log message.
      logPayload: false
      # -- Specify the name of the logger to use.
      loggerName: ConsumeError
      # -- Should the KSML application stop when a consume error occurs.
      stopOnError: true
    # -- Error handling settings for produce related errors.
    produce:
      # -- log a message when produce errors occur.
      log: true
      # -- Add the record payload to the log message.
      logPayload: false
      # -- Specify the name of the logger to use.
      loggerName: ProduceError
      # -- Should the KSML application stop when a consume error occurs.
      stopOnError: true
    # -- Error handling settings for processing related errors.
    process:
      # -- log a message when processing errors occur.
      log: true
      # -- Add the record payload to the log message.
      logPayload: false
      # -- Specify the name of the logger to use.
      loggerName: ProcessError
      # -- Should the KSML application stop when a consume error occurs.
      stopOnError: true

  # -- Data generation can be disabled for deployments to prevent accidental test data in non-test environments.
  producersEnabled: true
  # -- Pipelines can be disabled to allow for data-generation-only deployments.
  pipelinesEnabled: true

  # -- Map of the namespace and the KSML definition file executed in that namespace.
  definitions: {}
#  definitions:
#    ksml: ksml-definition.yaml
  # -- Map of Kafka connection properties and application id
  kafka: {}
#  kafka:
#    application.id: my-streaming-app
#    bootstrap.servers: "localhost:9092"
  # -- Map of available Schema Registries
  schemaRegistries: {}
    # Definition of an Apicurio schema registry
    # apicurio:
      # config:
        # Below is an example SSL configuration for Apicurio Serialization library from Apicurio documentation
        # apicurio.registry.request.ssl.keystore.location: /path/to/keystore.jks
        # apicurio.registry.request.ssl.keystore.type: JKS
        # apicurio.registry.request.ssl.keystore.password: password
        # apicurio.registry.request.ssl.key.password: password
        # apicurio.registry.request.ssl.truststore.location: /path/to/truststore.jks
        # apicurio.registry.request.ssl.truststore.type: JKS
        # apicurio.registry.request.ssl.truststore.password: password

    # Definition of a Confluent schema registry
    # confluent:
      # config:
        # Example SSL configuration for Confluent schema registry
        # schema.registry.ssl.protocol: TLSv1.3
        # schema.registry.ssl.enabled.protocols: TLSv1.3,TLSv1.2
        # schema.registry.ssl.endpoint.identification.algorithm: ""
        # schema.registry.ssl.keystore.location: /path/to/keystore.jks
        # schema.registry.ssl.keystore.type: JKS
        # schema.registry.ssl.key.password: password
        # schema.registry.ssl.keystore.password: password
        # schema.registry.ssl.truststore.location: /path/to/truststore.jks
        # schema.registry.ssl.truststore.type: JKS
        # schema.registry.ssl.truststore.password: password

  # -- Map of SerDes available to handle which notation types
  notations: {}
    # Definition for "avro" notation
    # avro:
      # type: confluent_avro          # For AVRO there are two implementations: apicurio_avro and confluent_avro
      # schemaRegistry: confluent
      # config:
        # Specify all properties to be passed into Confluent's KafkaAvroSerializer and KafkaAvroDeserializer
        # normalize.schemas: true
        # auto.register.schemas: false

    # Definition for "apicurio_avro" notation. With this entry, you can use a type like "apicurio_avro:SchemaName" in your
    # KSML definition, which then uses the Apicurio implementation for AVRO.
    # apicurio_avro:
      # type: apicurio_avro           # For AVRO there are two implementations: apicurio_avro and confluent_avro
      # schemaRegistry: apicurio
      # config:
      # Apicurio Avro serialisation settings
      # apicurio.registry.avro.encoding: "BINARY"
      # apicurio.registry.headers.enabled: "true"
      # apicurio.registry.serde.IdHandler: "io.apicurio.registry.serde.Default4ByteIdHandler"
      # apicurio.registry.schema-resolver: "io.apicurio.registry.resolver.DefaultSchemaResolver"

    # Definition for "apicurio_protobuf" notation. With this entry, you can use a type like "apicurio_protobuf:SchemaName" in your
    # KSML definition, which then uses the Apicurio implementation for ProtoBuf.
    # apicurio_protobuf:
    # type: apicurio_protobuf           # For AVRO there are two implementations: apicurio_protobuf and confluent_protobuf
    # schemaRegistry: apicurio
    # config:
    # Apicurio Avro serialisation settings


# -- KSML Pipeline or Producer definition files. See https://axual.github.io/ksml/introduction.html
ksmlDefinitions: {}
  # my-definition.yaml: |
  #   ...

# -- Schema definitions files. See https://github.com/Axual/ksml/tree/main/examples
schemaDefinitions: {}
  # my-schema.avsc: |
  #   ...

# -- The startup probe for the KSML containers.
startupProbe:
  httpGet:
    path: /startup
    port: http
  # -- Minimum consecutive failures for the probe to be considered failed.
  # A failed startupProbe will mark the container as unhealthy and trigger a restart for that specific container.
  failureThreshold: 30
  # -- Number of seconds after the container has started before startup probes are initiated.
  initialDelaySeconds: 2
  # -- How often (in seconds) to perform the probe.
  periodSeconds: 1
  # -- Minimum consecutive successes for the probe to be considered successful after having failed.
  successThreshold: 1
  # -- Number of seconds after which the probe times out.
  timeoutSeconds: 1

# -- The readiness probe for the KSML containers.
readinessProbe:
  # -- The service definition to call to determine readiness.
  httpGet:
    path: /ready
    port: http
  # -- Minimum consecutive failures for the probe to be considered failed after having succeeded.
  # A failed readinessProbe will cause the container to move to the `NotReady` state.
  failureThreshold: 4
  # -- Number of seconds after the container has started before readiness probes are initiated.
  initialDelaySeconds: 20
  # -- How often (in seconds) to perform the probe.
  periodSeconds: 10
  # -- Minimum consecutive successes for the probe to be considered successful after having failed.
  successThreshold: 1
  # -- Number of seconds after which the probe times out.
  timeoutSeconds: 1

# -- The readiness probe for the KSML containers.
livenessProbe:
  # -- The service definition to call to determine liveness.
  httpGet:
    path: /live
    port: http
  # -- Minimum consecutive failures for the probe to be considered failed after having succeeded.
  # A failed livenessProbe will cause the container to be restarted.
  failureThreshold: 4
  # -- Number of seconds after the container has started before liveness probes are initiated.
  initialDelaySeconds: 30
  # -- How often (in seconds) to perform the probe.
  periodSeconds: 10
  # -- Minimum consecutive successes for the probe to be considered successful after having failed.
  successThreshold: 1
  # -- Number of seconds after which the probe times out.
  timeoutSeconds: 1

serviceAccount:
  # -- Specifies whether a service account should be created.
  create: true
  # -- Automatically mount a ServiceAccount's API credentials
  automount: true
  # -- Annotations to add to the service account.
  annotations: {}
  # -- The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template.
  name: ""

# -- Extra annotations to add to the Pods.
podAnnotations: {}

# -- Extra labels to add to the Pods.
podLabels: {}

# -- Pod-level security attributes and common container settings.
podSecurityContext: {}
  # fsGroup: 2000

# -- Defines the security options the container should be run with.
# If set, the fields of SecurityContext override the equivalent fields of PodSecurityContext.
# @default -- See `values.yaml` file.
securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

service:
  type: ClusterIP
  port: 80

ingress:
  # -- Enable creation of the Ingress resource to expose this service.
  enabled: false
  # -- The name of the IngressClass cluster resource.
  # The associated IngressClass defines which controller will implement the resource.
  className: ""
  # -- Annotations to add to the Ingress resource.
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  # -- TLS configuration for this Ingress.
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: "1000m"
  #   memory: "768Mi"
  # requests:
  #   cpu: "500m"
  #   memory: "128Mi"

# -- Additional volumes on the output Deployment definition.
volumes: []
# - name: foo
#   secret:
#     secretName: mysecret
#     optional: false

# -- Additional volumeMounts on the output Deployment definition.
volumeMounts: []
# - name: foo
#   mountPath: "/etc/foo"
#   readOnly: true

# -- Additional volumeClaimTemplates for the stateful.
volumeClaimTemplates: []

# -- Selector which must match a node's labels for the pod to be scheduled on that node.
nodeSelector: {}

# -- The tolerations on this pod. See the Kubernetes documentation on [Taints and Tolerations](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/).
tolerations: []

# -- The pod's scheduling constraints. See the Kubernetes documentation on [Affinity and Anti-affinity](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity).
affinity: {}

# -- Describes how a group of pods ought to spread across topology domains. See the Kubernetes documentation on [Pod Topology Spread Constraints](https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/).
topologySpreadConstraints: []

# -- KSML application server port defined in the StatefulSet/Job.
applicationServer:
  # -- Start an application server for the component.
  enabled: true
  # -- Port on which Application server should be initialized.
  port: "8080"

# -- Logging configuration settings for KSML.
logging:
  # -- Location of the logging configuration file.
  configFile: '/ksml-logging/logback.xml'
  # -- Enable JSON logging.
  jsonEnabled: false
  # -- The logback log pattern to use.
  patterns:
    stdout: '%date{"yyyy-MM-dd''T''HH:mm:ss,SSSXXX", UTC} [%t] %-5level %logger{36} - %msg%n'
    stderr: '%date{"yyyy-MM-dd''T''HH:mm:ss,SSSXXX", UTC} [%t] %-5level %logger{36} - %msg%n'
  # -- The default log level to use for all loggers
  rootLogLevel: INFO
  # -- Specify log levels for specific loggers.
  loggers: {}
  # -- Specify default loggers set for all deployments to minimize excessive logging.
  defaultLoggers:
    io.axual.ksml: INFO
    org.apache.kafka: WARN
    org.apache.kafka.clients.consumer.ConsumerConfig: WARN
    org.apache.kafka.clients.producer.ProducerConfig: WARN
    org.apache.kafka.clients.admin.AdminClientConfig: WARN
    org.apache.kafka.streams.StreamsConfig: WARN
    io.confluent: WARN

# -- Configure the storage specification for the volumeClaimTemplates.
store:
  # -- Specifications of the volumeClaimTemplate.
  spec: {}
#    accessModes: [ "ReadWriteOnce" ]
#    resources:
#      requests:
#        storage: 1Gi

prometheus:
  # -- KSML prometheus server port defined in the StatefulSet/Job. Note that this must match the port defined in ksmlRunnerConfig.
  enabled: false
  # -- Port on which Prometheus metrics endpoint should be initialized.
  port: "9999"
  # -- Contents of the JMX exporter config file.
  config:
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    rules:
      - pattern: 'ksml<type=app-info, app-id=(.+), app-name=(.+), app-version=(.+), build-time=(.+)>Value:'
        name: ksml_app
        labels:
          app_id: "$1"
          name: "$2"
          version: "$3"
          build_time: "$4"
        type: GAUGE
        value: 1
        cached: true
      - pattern: 'ksml<type=user_defined_counter, .*>'
        type: COUNTER
      - pattern: 'ksml<type=.+, .*>'
        type: GAUGE
      - pattern: 'kafka.streams<type=stream-(.+-)?metrics, .*>'
        type: GAUGE
      - pattern: 'kafka.producer<type=producer-(.+-)?metrics, .*>'
        type: GAUGE
      - pattern: 'kafka.consumer<type=consumer-(.+-)?metrics, .*>'
        type: GAUGE
      - pattern: 'kafka.admin.client<type=admin-client-(.+-)?metrics, .*>'
        type: GAUGE
      - pattern: 'java.lang<type=OperatingSystem><>(committed_virtual_memory|free_physical_memory|free_swap_space|total_physical_memory|total_swap_space)_size:'
        name: os_$1_bytes
        type: GAUGE
        attrNameSnakeCase: true
      - pattern: 'java.lang<type=OperatingSystem><>((?!process_cpu_time)\w+):'
        name: os_$1
        type: GAUGE
        attrNameSnakeCase: true

prometheusRule:
  # -- Enables creation of Prometheus Operator [PrometheusRule](https://prometheus-operator.dev/docs/api-reference/api/#monitoring.coreos.com/v1.PrometheusRule).
  # Ignored if API `monitoring.coreos.com/v1` is not available or if prometheus is disabled.
  enabled: false
  # -- Determines how often rules in the group are evaluated.
  interval: ""
  # -- Additional labels for the PrometheusRules.
  labels: {}
  defaultRules:
    # -- Enables the default prometheusRules.
    # The `{{ include "ksml.fullname" . }} is down` rule requires the `serviceMonitor.enabled=true` to function.
    enabled: true
    # -- Customize the labels to the default prometheusRules.
    labels: {}
  # -- A list alerting or recording rules to include on top of the defaults. These fields are templated.
  extraRules:
#    - alert: MyAlertName
#      annotations:
#        summary: Summary of my alert
#        description: Longer description of my alert that goes into a bit more detail
#      expr: Expression that could use the helpers functions
#      for: Time for which this rule is evaluated before been fired
#      labels:
#        your-label-key: your-label-value

serviceMonitor:
  # -- Enables creation of Prometheus Operator [ServiceMonitor](https://prometheus-operator.dev/docs/api-reference/api/#monitoring.coreos.com/v1.ServiceMonitor).
  # Ignored if API `monitoring.coreos.com/v1` is not available or if prometheus is disabled.
  enabled: false
  # -- Interval at which metrics should be scraped.
  interval: 30s
  # -- Timeout after which the scrape is ended.
  scrapeTimeout: 10s
  # -- Additional labels for the ServiceMonitor.
  labels: {}

networkPolicy:
  # -- Enables creation of Network policies to declare for the ksml pod.
  # See the Kubernetes documentation on [NetworkPolicy](https://kubernetes.io/docs/tasks/administer-cluster/declare-network-policy/).
  enabled: false
  # -- Network Policy Ingress's Configuration.
  ingress:
    - {}
  # -- Network Policy Egress's Configuration.
  egress:
    - {}
