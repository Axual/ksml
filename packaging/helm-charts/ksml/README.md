# ksml

![Version: 1.1.0-SNAPSHOT](https://img.shields.io/badge/Version-1.1.0--SNAPSHOT-informational?style=flat-square) ![Type: application](https://img.shields.io/badge/Type-application-informational?style=flat-square) ![AppVersion: 1.0-snapshot](https://img.shields.io/badge/AppVersion-1.0--snapshot-informational?style=flat-square)

[KSML](https://ksml.io) - Kafka Streaming for Low Code Environments

* [Introduction](#introduction)
* [Prerequisites](#prerequisites)
* [Installing the Chart](#installing-the-chart)
* [Uninstalling the Chart](#uninstalling-the-chart)
* [Deployment modes](#deployment-modes)
  * [StatefulSet deployments for pipelines](#statefulset-deployment-for-pipeline-processing)
  * [Job deployments for data generators](#job-deployment-for-data-generators)
* [Configuration](#configuration)
* [Examples](#examples)
  * [Plain Kafka SASL Connection](#plain-kafka-sasl-connection)
  * [Axual Kafka SASL Connection](#axual-kafka-sasl-connection)
  * [Run as a Kubernetes Job](#example-run-ksml-as-a-kubernetes-job)

## Introduction

This chart deploys an easy way to define, run and deploy KSML applications on
a [Kubernetes](http://kubernetes.io) cluster using the [Helm](https://helm.sh) package manager.

## Prerequisites

- Kubernetes v1.21+

## Installing the Chart

To install/upgrade the chart with the release name `ksml`:

```bash
$ helm upgrade -i ksml oci://registry.axual.io/opensource/charts/ksml -n streaming --create-namespace --version=| 0.0.0-snapshot
```

The command deploys An easy way to define, run and deploy Kafka streaming applications on the
Kubernetes cluster in the default configuration. The [configuration](#configuration) section lists
the parameters that can be configured during installation.

> **Tip**: List all releases using `helm list`

## Uninstalling the Chart

To uninstall the `ksml`:

```bash
$ helm uninstall ksml -n streaming
```

The command removes all the Kubernetes components associated with the chart and deletes the release.

## Deployment Modes

KSML offers both data generation and pipeline processing logic. To better support these use cases,
Deployment modes have been introduced, controlled by the `deploymentMode` configuration value

### StatefulSet deployment for pipeline processing

By default, a KSML application deployed with this chart will run as a Kubernetes `StatefulSet`.
This enables predictable horizontal scaling and identities for the replicas.

A `StatefulSet` deployment will always try to meet the number of running replicas, and will restart if the
KSML application completed successfully.

### Job deployment for data generators

The `Job` deployment mode will start the KSML application as a Kubernetes `Job`.

The created KSML job will run once and won't restart on failure or successful completion.
This is invaluable for data generators which are defined with an end clause.
This allows application owners to check the deployment data and logs even after completion.

> **Warning**: The `replicas` and `volumeClaimTemplates` configuration options are ignored for Job
> deployments.

> **Warning**: Job deployments cannot be updated and must be removed and recreated.

## Configuration

The following table lists the configurable parameters of the `ksml` chart and their default values.

| Parameter                                          | Type | Default | Description |
|----------------------------------------------------|------|---------|-------------|
| affinity                                           | object | `{}` | The pod's scheduling constraints. See the Kubernetes documentation on [Affinity and Anti-affinity](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity). |
| applicationServer                                  | object | `{"enabled":true,"port":"8080"}` | KSML application server port defined in the StatefulSet/Job. |
| applicationServer.enabled                          | bool | `true` | Start an application server for the component. |
| applicationServer.port                             | string | `"8080"` | Port on which Application server should be initialized. |
| deploymentMode                                     | string | `"StatefulSet"` | Define the k8s-resource selected to deploy the KSML Runner. |
| fullnameOverride                                   | string | `""` | Override the fully qualified app name generated by the chart. |
| image.pullPolicy                                   | string | `"IfNotPresent"` | One of `Always`, `IfNotPresent`, or `Never`. |
| image.repository                                   | string | `"registry.axual.io/opensource/images/axual/ksml"` | Registry to pull the image from and the name of the image. |
| image.tag                                          | string | `""` | Override the image tag whose default is the chart `appVersion`. |
| imagePullSecrets                                   | list | `[]` | Override the list of ImagePullSecrets provided. |
| ingress.annotations                                | object | `{}` | Annotations to add to the Ingress resource. |
| ingress.className                                  | string | `""` | The name of the IngressClass cluster resource. The associated IngressClass defines which controller will implement the resource. |
| ingress.enabled                                    | bool | `false` | Enable creation of the Ingress resource to expose this service. |
| ingress.hosts[0].host                              | string | `"chart-example.local"` |  |
| ingress.hosts[0].paths[0].path                     | string | `"/"` |  |
| ingress.hosts[0].paths[0].pathType                 | string | `"ImplementationSpecific"` |  |
| ingress.tls                                        | list | `[]` | TLS configuration for this Ingress. |
| job                                                | object | `{"finalizers":[],"pod":{"finalizers":[]},"ttlSecondsAfterFinished":259200}` | Job deployment specific settings. |
| job.finalizers                                     | list | `[]` | Allows custom finalizers to be set on the job resource. |
| job.pod                                            | object | `{"finalizers":[]}` | pod specific configurations. |
| job.pod.finalizers                                 | list | `[]` | Allows custom finalizers to be set on the pod created by the job. |
| job.ttlSecondsAfterFinished                        | int | `259200` | Clean up a completed or failed job after 3 days. This allows for KSML inspection after completion. |
| ksmlDefinitions                                    | object | `{}` | KSML Pipeline or Producer definition files. See https://axual.github.io/ksml/introduction.html |
| ksmlRunnerConfig                                   | object | `{"createStorageDirectory":true,"definitionDirectory":"/ksml","definitions":{},"errorHandling":{"consume":{"log":true,"logPayload":false,"loggerName":"ConsumeError","stopOnError":true},"process":{"log":true,"logPayload":false,"loggerName":"ProcessError","stopOnError":true},"produce":{"log":true,"logPayload":false,"loggerName":"ProduceError","stopOnError":true}},"kafka":{},"pipelinesEnabled":true,"producersEnabled":true,"schemaDirectory":"/ksml","storageDirectory":"/ksml-store/data"}` | KSML runner configuration. See https://axual.github.io/ksml/runners.html |
| ksmlRunnerConfig.createStorageDirectory            | bool | `true` | Create the storageDirectory if it does not exist. |
| ksmlRunnerConfig.definitionDirectory               | string | `"/ksml"` | Directory containing KSML Definition files. This should only be changed if an external volume mount is used. |
| ksmlRunnerConfig.definitions                       | object | `{}` | Map of the namespace and the KSML definition file executed in that namespace. |
| ksmlRunnerConfig.errorHandling                     | object | `{"consume":{"log":true,"logPayload":false,"loggerName":"ConsumeError","stopOnError":true},"process":{"log":true,"logPayload":false,"loggerName":"ProcessError","stopOnError":true},"produce":{"log":true,"logPayload":false,"loggerName":"ProduceError","stopOnError":true}}` | KSML Error handling settings. Error Handling can be defined for consume, produce and processing errors. |
| ksmlRunnerConfig.errorHandling.consume             | object | `{"log":true,"logPayload":false,"loggerName":"ConsumeError","stopOnError":true}` | Error handling settings for consume related errors. |
| ksmlRunnerConfig.errorHandling.consume.log         | bool | `true` | log a message when consume errors occur. |
| ksmlRunnerConfig.errorHandling.consume.logPayload  | bool | `false` | Add the record payload to the log message. |
| ksmlRunnerConfig.errorHandling.consume.loggerName  | string | `"ConsumeError"` | Specify the name of the logger to use. |
| ksmlRunnerConfig.errorHandling.consume.stopOnError | bool | `true` | Should the KSML application stop when a consume error occurs. |
| ksmlRunnerConfig.errorHandling.process             | object | `{"log":true,"logPayload":false,"loggerName":"ProcessError","stopOnError":true}` | Error handling settings for processing related errors. |
| ksmlRunnerConfig.errorHandling.process.log         | bool | `true` | log a message when processing errors occur. |
| ksmlRunnerConfig.errorHandling.process.logPayload  | bool | `false` | Add the record payload to the log message. |
| ksmlRunnerConfig.errorHandling.process.loggerName  | string | `"ProcessError"` | Specify the name of the logger to use. |
| ksmlRunnerConfig.errorHandling.process.stopOnError | bool | `true` | Should the KSML application stop when a consume error occurs. |
| ksmlRunnerConfig.errorHandling.produce             | object | `{"log":true,"logPayload":false,"loggerName":"ProduceError","stopOnError":true}` | Error handling settings for produce related errors. |
| ksmlRunnerConfig.errorHandling.produce.log         | bool | `true` | log a message when produce errors occur. |
| ksmlRunnerConfig.errorHandling.produce.logPayload  | bool | `false` | Add the record payload to the log message. |
| ksmlRunnerConfig.errorHandling.produce.loggerName  | string | `"ProduceError"` | Specify the name of the logger to use. |
| ksmlRunnerConfig.errorHandling.produce.stopOnError | bool | `true` | Should the KSML application stop when a consume error occurs. |
| ksmlRunnerConfig.kafka                             | object | `{}` | Map of Kafka connection properties and application id |
| ksmlRunnerConfig.pipelinesEnabled                  | bool | `true` | Pipelines can be disabled to allow for data-generation-only deployments. |
| ksmlRunnerConfig.producersEnabled                  | bool | `true` | Data generation can be disabled for deployments to prevent accidental test data in non-test environments. |
| ksmlRunnerConfig.schemaDirectory                   | string | `"/ksml"` | Directory containing the Schema files. This should only be changed if an external volume mount is used. |
| ksmlRunnerConfig.storageDirectory                  | string | `"/ksml-store/data"` | Directory containing the stateful data. This should only be changed if an external volume mount is used. |
| livenessProbe                                      | object | `{"failureThreshold":4,"httpGet":{"path":"/live","port":"http"},"initialDelaySeconds":30,"periodSeconds":10,"successThreshold":1,"timeoutSeconds":1}` | The readiness probe for the KSML containers. |
| livenessProbe.failureThreshold                     | int | `4` | Minimum consecutive failures for the probe to be considered failed after having succeeded. A failed livenessProbe will cause the container to be restarted. |
| livenessProbe.httpGet                              | object | `{"path":"/live","port":"http"}` | The service definition to call to determine liveness. |
| livenessProbe.initialDelaySeconds                  | int | `30` | Number of seconds after the container has started before liveness probes are initiated. |
| livenessProbe.periodSeconds                        | int | `10` | How often (in seconds) to perform the probe. |
| livenessProbe.successThreshold                     | int | `1` | Minimum consecutive successes for the probe to be considered successful after having failed. |
| livenessProbe.timeoutSeconds                       | int | `1` | Number of seconds after which the probe times out. |
| logging                                            | object | `{"configFile":"/ksml-logging/logback.xml","defaultLoggers":{"io.axual.ksml":"INFO","io.confluent":"WARN","org.apache.kafka":"WARN","org.apache.kafka.clients.admin.AdminClientConfig":"WARN","org.apache.kafka.clients.consumer.ConsumerConfig":"WARN","org.apache.kafka.clients.producer.ProducerConfig":"WARN","org.apache.kafka.streams.StreamsConfig":"WARN"},"jsonEnabled":false,"loggers":{},"patterns":{"stderr":"%date{\"yyyy-MM-dd'T'HH:mm:ss,SSSXXX\", UTC} [%t] %-5level %logger{36} - %msg%n","stdout":"%date{\"yyyy-MM-dd'T'HH:mm:ss,SSSXXX\", UTC} [%t] %-5level %logger{36} - %msg%n"},"rootLogLevel":"INFO"}` | Logging configuration settings for KSML. |
| logging.configFile                                 | string | `"/ksml-logging/logback.xml"` | Location of the logging configuration file. |
| logging.defaultLoggers                             | object | `{"io.axual.ksml":"INFO","io.confluent":"WARN","org.apache.kafka":"WARN","org.apache.kafka.clients.admin.AdminClientConfig":"WARN","org.apache.kafka.clients.consumer.ConsumerConfig":"WARN","org.apache.kafka.clients.producer.ProducerConfig":"WARN","org.apache.kafka.streams.StreamsConfig":"WARN"}` | Specify default loggers set for all deployments to minimize excessive logging. |
| logging.jsonEnabled                                | bool | `false` | Enable JSON logging. |
| logging.loggers                                    | object | `{}` | Specify log levels for specific loggers. |
| logging.patterns                                   | object | `{"stderr":"%date{\"yyyy-MM-dd'T'HH:mm:ss,SSSXXX\", UTC} [%t] %-5level %logger{36} - %msg%n","stdout":"%date{\"yyyy-MM-dd'T'HH:mm:ss,SSSXXX\", UTC} [%t] %-5level %logger{36} - %msg%n"}` | The logback log pattern to use. |
| logging.rootLogLevel                               | string | `"INFO"` | The default log level to use for all loggers |
| nameOverride                                       | string | `""` | Override the app name generated by the chart. |
| networkPolicy.egress                               | list | `[{}]` | Network Policy Egress's Configuration. |
| networkPolicy.enabled                              | bool | `false` | Enables creation of Network policies to declare for the ksml pod. See the Kubernetes documentation on [NetworkPolicy](https://kubernetes.io/docs/tasks/administer-cluster/declare-network-policy/). |
| networkPolicy.ingress                              | list | `[{}]` | Network Policy Ingress's Configuration. |
| nodeSelector                                       | object | `{}` | Selector which must match a node's labels for the pod to be scheduled on that node. |
| podAnnotations                                     | object | `{}` | Extra annotations to add to the Pods. |
| podLabels                                          | object | `{}` | Extra labels to add to the Pods. |
| podSecurityContext                                 | object | `{}` | Pod-level security attributes and common container settings. |
| prometheus.config                                  | object | `{"lowercaseOutputLabelNames":true,"lowercaseOutputName":true,"rules":[{"cached":true,"labels":{"app_id":"$1","build_time":"$4","name":"$2","version":"$3"},"name":"ksml_app","pattern":"ksml<type=app-info, app-id=(.+), app-name=(.+), app-version=(.+), build-time=(.+)>Value:","type":"GAUGE","value":1},{"pattern":"ksml<type=user_defined_counter, .*>","type":"COUNTER"},{"pattern":"ksml<type=.+, .*>","type":"GAUGE"},{"pattern":"kafka.streams<type=stream-(.+-)?metrics, .*>","type":"GAUGE"},{"pattern":"kafka.producer<type=producer-(.+-)?metrics, .*>","type":"GAUGE"},{"pattern":"kafka.consumer<type=consumer-(.+-)?metrics, .*>","type":"GAUGE"},{"pattern":"kafka.admin.client<type=admin-client-(.+-)?metrics, .*>","type":"GAUGE"},{"attrNameSnakeCase":true,"name":"os_$1_bytes","pattern":"java.lang<type=OperatingSystem><>(committed_virtual_memory|free_physical_memory|free_swap_space|total_physical_memory|total_swap_space)_size:","type":"GAUGE"},{"attrNameSnakeCase":true,"name":"os_$1","pattern":"java.lang<type=OperatingSystem><>((?!process_cpu_time)\\w+):","type":"GAUGE"}]}` | Contents of the JMX exporter config file. |
| prometheus.enabled                                 | bool | `false` | KSML prometheus server port defined in the StatefulSet/Job. Note that this must match the port defined in ksmlRunnerConfig. |
| prometheus.port                                    | string | `"9999"` | Port on which Prometheus metrics endpoint should be initialized. |
| prometheusRule.defaultRules.enabled                | bool | `true` | Enables the default prometheusRules. The `{{ include "ksml.fullname" . }} is down` rule requires the `serviceMonitor.enabled=true` to function. |
| prometheusRule.defaultRules.labels                 | object | `{}` | Customize the labels to the default prometheusRules. |
| prometheusRule.enabled                             | bool | `false` | Enables creation of Prometheus Operator [PrometheusRule](https://prometheus-operator.dev/docs/api-reference/api/#monitoring.coreos.com/v1.PrometheusRule). Ignored if API `monitoring.coreos.com/v1` is not available or if prometheus is disabled. |
| prometheusRule.extraRules                          | string | `nil` | A list alerting or recording rules to include on top of the defaults. These fields are templated. |
| prometheusRule.interval                            | string | `""` | Determines how often rules in the group are evaluated. |
| prometheusRule.labels                              | object | `{}` | Additional labels for the PrometheusRules. |
| readinessProbe                                     | object | `{"failureThreshold":4,"httpGet":{"path":"/ready","port":"http"},"initialDelaySeconds":20,"periodSeconds":10,"successThreshold":1,"timeoutSeconds":1}` | The readiness probe for the KSML containers. |
| readinessProbe.failureThreshold                    | int | `4` | Minimum consecutive failures for the probe to be considered failed after having succeeded. A failed readinessProbe will cause the container to move to the `NotReady` state. |
| readinessProbe.httpGet                             | object | `{"path":"/ready","port":"http"}` | The service definition to call to determine readiness. |
| readinessProbe.initialDelaySeconds                 | int | `20` | Number of seconds after the container has started before readiness probes are initiated. |
| readinessProbe.periodSeconds                       | int | `10` | How often (in seconds) to perform the probe. |
| readinessProbe.successThreshold                    | int | `1` | Minimum consecutive successes for the probe to be considered successful after having failed. |
| readinessProbe.timeoutSeconds                      | int | `1` | Number of seconds after which the probe times out. |
| replicaCount                                       | int | `1` |  |
| resources                                          | object | `{}` |  |
| schemaDefinitions                                  | object | `{}` | Schema definitions files. See https://github.com/Axual/ksml/tree/main/examples |
| securityContext                                    | object | See `values.yaml` file. | Defines the security options the container should be run with. If set, the fields of SecurityContext override the equivalent fields of PodSecurityContext. |
| service.port                                       | int | `80` |  |
| service.type                                       | string | `"ClusterIP"` |  |
| serviceAccount.annotations                         | object | `{}` | Annotations to add to the service account. |
| serviceAccount.automount                           | bool | `true` | Automatically mount a ServiceAccount's API credentials |
| serviceAccount.create                              | bool | `true` | Specifies whether a service account should be created. |
| serviceAccount.name                                | string | `""` | The name of the service account to use. If not set and create is true, a name is generated using the fullname template. |
| serviceMonitor.enabled                             | bool | `false` | Enables creation of Prometheus Operator [ServiceMonitor](https://prometheus-operator.dev/docs/api-reference/api/#monitoring.coreos.com/v1.ServiceMonitor). Ignored if API `monitoring.coreos.com/v1` is not available or if prometheus is disabled. |
| serviceMonitor.interval                            | string | `"30s"` | Interval at which metrics should be scraped. |
| serviceMonitor.labels                              | object | `{}` | Additional labels for the ServiceMonitor. |
| serviceMonitor.scrapeTimeout                       | string | `"10s"` | Timeout after which the scrape is ended. |
| startupProbe                                       | object | `{"failureThreshold":30,"httpGet":{"path":"/startup","port":"http"},"initialDelaySeconds":2,"periodSeconds":1,"successThreshold":1,"timeoutSeconds":1}` | The startup probe for the KSML containers. |
| startupProbe.failureThreshold                      | int | `30` | Minimum consecutive failures for the probe to be considered failed. A failed startupProbe will mark the container as unhealthy and trigger a restart for that specific container. |
| startupProbe.initialDelaySeconds                   | int | `2` | Number of seconds after the container has started before startup probes are initiated. |
| startupProbe.periodSeconds                         | int | `1` | How often (in seconds) to perform the probe. |
| startupProbe.successThreshold                      | int | `1` | Minimum consecutive successes for the probe to be considered successful after having failed. |
| startupProbe.timeoutSeconds                        | int | `1` | Number of seconds after which the probe times out. |
| store                                              | object | `{"spec":{}}` | Configure the storage specification for the volumeClaimTemplates. |
| store.spec                                         | object | `{}` | Specifications of the volumeClaimTemplate. |
| tolerations                                        | list | `[]` | The tolerations on this pod. See the Kubernetes documentation on [Taints and Tolerations](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/). |
| topologySpreadConstraints                          | list | `[]` | Describes how a group of pods ought to spread across topology domains. See the Kubernetes documentation on [Pod Topology Spread Constraints](https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/). |
| volumeClaimTemplates                               | list | `[]` | Additional volumeClaimTemplates for the stateful. |
| volumeMounts                                       | list | `[]` | Additional volumeMounts on the output Deployment definition. |
| volumes                                            | list | `[]` | Additional volumes on the output Deployment definition. |


Specify each parameter using the `--set key=value[,key=value]` argument to `helm upgrade -i`. For
example:

```bash
$ helm upgrade -i ksml oci://registry.axual.io/opensource/charts/ksml -n streaming --create-namespace --version=| 0.0.0-snapshot --set replicaCount=1
```

Alternatively, a YAML file that specifies the values for the parameters can be provided while
installing the chart. For example:

```bash
$ helm upgrade -i ksml oci://registry.axual.io/opensource/charts/ksml -n streaming --create-namespace --version=| 0.0.0-snapshot --values values.yaml
```

## Examples

### Plain Kafka SASL Connection

<details>
  <summary>Example configuration plain Kafka SASL </summary>

```YAML
image:
  tag: snapshot

replicaCount: 3

resources:
  requests:
    memory: "128Mi"
    cpu: "250m"
  limits:
    memory: "768Mi"
    cpu: "500m"

ksmlRunnerConfig:
  definitions:
    generate: generator.yaml
  kafka:
    application.id: example.datagen

    bootstrap.servers: 'testing-sasl-broker:9095'
    security.protocol: SASL_SSL
    sasl.mechanism: SCRAM-SHA-512
    sasl.jaas.config: 'org.apache.kafka.common.security.scram.ScramLoginModule required username=example_user password=12345678 ;'

ksmlDefinitions:
  generator.yaml: |
    # This example shows how to generate data and have it sent to a target topic in a given format.

    functions:
      generate_sensordata_message:
        type: generator
        globalCode: |
          import time
          import random
          sensorCounter = 0
        code: |
          global sensorCounter

          key = "sensor"+str(sensorCounter)           # Set the key to return ("sensor0" to "sensor9")
          sensorCounter = (sensorCounter+1) % 10      # Increase the counter for next iteration

          # Generate some random sensor measurement data
          types = { 0: { "type": "AREA", "unit": random.choice([ "m2", "ft2" ]), "value": str(random.randrange(1000)) },
                    1: { "type": "HUMIDITY", "unit": random.choice([ "g/m3", "%" ]), "value": str(random.randrange(100)) },
                    2: { "type": "LENGTH", "unit": random.choice([ "m", "ft" ]), "value": str(random.randrange(1000)) },
                    3: { "type": "STATE", "unit": "state", "value": random.choice([ "off", "on" ]) },
                    4: { "type": "TEMPERATURE", "unit": random.choice([ "C", "F" ]), "value": str(random.randrange(-100, 100)) }
                  }

          # Build the result value using any of the above measurement types
          value = { "name": key, "timestamp": str(round(time.time()*1000)), **random.choice(types) }
          value["color"] = random.choice([ "black", "blue", "red", "yellow", "white" ])
          value["owner"] = random.choice([ "Alice", "Bob", "Charlie", "Dave", "Evan" ])
          value["city"] = random.choice([ "Amsterdam", "Xanten", "Utrecht", "Alkmaar", "Leiden" ])

          if random.randrange(10) == 0:
            value = None
        expression: (key, value)                      # Return a message tuple with the key and value
        resultType: (string, json)                    # Indicate the type of key and value

    producers:
      sensordata_json_producer:
        generator: generate_sensordata_message
        interval: 444
        to:
          topic: ksml_sensordata_json
          keyType: string
          valueType: json

applicationServer:
  enabled: true
  port: "8080"

prometheus:
  enabled: true
  port: "9993"
  config:
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    rules:
      - pattern: 'ksml<type=app-info, app-id=(.+), app-name=(.+), app-version=(.+), build-time=(.+)>Value:'
        name: ksml_app_info
        labels:
          app_id: "$1"
          name: "$2"
          version: "$3"
          build_time: "$4"
        type: GAUGE
        value: 1
        cached: true
      - pattern: .*

logging:
  configFile: '/ksml-logging/logback.xml'
  jsonEnabled: false
  patterns:
    stdout: '%date{"yyyy-MM-dd''T''HH:mm:ss,SSSXXX", UTC} %-5level %logger{36} - %msg%n'
    stderr: '%date{"yyyy-MM-dd''T''HH:mm:ss,SSSXXX", UTC} %-5level %logger{36} - %msg%n'
  loggers:
    org.apache.kafka: INFO
    org.apache.kafka.streams.StreamsConfig: INFO
    org.apache.kafka.clients.consumer.ConsumerConfig: INFO

```

</details>

### Axual Kafka SASL Connection

<details>
  <summary>Example configuration to connect to an Axual Kafka cluster</summary>
See the ksmlRunnerConfig.kafka section for the special additions to automatically resolve resource names to the Axual namespaces

```YAML
image:
  tag: snapshot

replicaCount: 3

resources:
  requests:
    memory: "128Mi"
    cpu: "250m"
  limits:
    memory: "768Mi"
    cpu: "500m"

ksmlRunnerConfig:
  definitions:
    generate: generator.yaml
  kafka:
    application.id: example.datagen

    bootstrap.servers: 'testing-sasl-broker.axual.cloud:9095'
    security.protocol: SASL_SSL
    sasl.mechanism: SCRAM-SHA-512
    sasl.jaas.config: 'org.apache.kafka.common.security.scram.ScramLoginModule required username=example_user password=12345678 ;'

    # Use these configuration properties when connecting to a cluster using the Axual naming patterns.
    # These patterns are resolved into the actual name used on Kafka using the values in this configuration map
    # and the topic names specified in the definition YAML files

    tenant: 'custom'
    instance: 'dta'
    environment: 'test'
    group.id.pattern: '{tenant}-{instance}-{environment}-{group.id}'
    topic.pattern: '{tenant}-{instance}-{environment}-{topic}'
    transactional.id.pattern: '{tenant}-{instance}-{environment}-{transactional.id}'

ksmlDefinitions:
  generator.yaml: |
    # This example shows how to generate data and have it sent to a target topic in a given format.

    functions:
      generate_sensordata_message:
        type: generator
        globalCode: |
          import time
          import random
          sensorCounter = 0
        code: |
          global sensorCounter

          key = "sensor"+str(sensorCounter)           # Set the key to return ("sensor0" to "sensor9")
          sensorCounter = (sensorCounter+1) % 10      # Increase the counter for next iteration

          # Generate some random sensor measurement data
          types = { 0: { "type": "AREA", "unit": random.choice([ "m2", "ft2" ]), "value": str(random.randrange(1000)) },
                    1: { "type": "HUMIDITY", "unit": random.choice([ "g/m3", "%" ]), "value": str(random.randrange(100)) },
                    2: { "type": "LENGTH", "unit": random.choice([ "m", "ft" ]), "value": str(random.randrange(1000)) },
                    3: { "type": "STATE", "unit": "state", "value": random.choice([ "off", "on" ]) },
                    4: { "type": "TEMPERATURE", "unit": random.choice([ "C", "F" ]), "value": str(random.randrange(-100, 100)) }
                  }

          # Build the result value using any of the above measurement types
          value = { "name": key, "timestamp": str(round(time.time()*1000)), **random.choice(types) }
          value["color"] = random.choice([ "black", "blue", "red", "yellow", "white" ])
          value["owner"] = random.choice([ "Alice", "Bob", "Charlie", "Dave", "Evan" ])
          value["city"] = random.choice([ "Amsterdam", "Xanten", "Utrecht", "Alkmaar", "Leiden" ])

          if random.randrange(10) == 0:
            value = None
        expression: (key, value)                      # Return a message tuple with the key and value
        resultType: (string, json)                    # Indicate the type of key and value

    producers:
      sensordata_json_producer:
        generator: generate_sensordata_message
        interval: 444
        to:
          topic: ksml_sensordata_json
          keyType: string
          valueType: json

applicationServer:
  enabled: true
  port: "8080"

prometheus:
  enabled: true
  port: "9993"
  config:
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    rules:
      - pattern: 'ksml<type=app-info, app-id=(.+), app-name=(.+), app-version=(.+), build-time=(.+)>Value:'
        name: ksml_app_info
        labels:
          app_id: "$1"
          name: "$2"
          version: "$3"
          build_time: "$4"
        type: GAUGE
        value: 1
        cached: true
      - pattern: .*

logging:
  configFile: '/ksml-logging/logback.xml'
  jsonEnabled: false
  patterns:
    stdout: '%date{"yyyy-MM-dd''T''HH:mm:ss,SSSXXX", UTC} %-5level %logger{36} - %msg%n'
    stderr: '%date{"yyyy-MM-dd''T''HH:mm:ss,SSSXXX", UTC} %-5level %logger{36} - %msg%n'
  loggers:
    org.apache.kafka: INFO
    org.apache.kafka.streams.StreamsConfig: INFO
    org.apache.kafka.clients.consumer.ConsumerConfig: INFO
```

</details>

### Example: Run KSML as a Kubernetes Job

<details>
  <summary>Example configuration to deploy the KSML application as a Job</summary>
By deploying as a job the pod running the KSML code will not restart on completion of the pods.

```YAML
image:
  tag: "snapshot"

deploymentMode: "Job"

resources:
  requests:
    memory: "128Mi"
    cpu: "250m"
  limits:
    memory: "768Mi"
    cpu: "500m"

ksmlRunnerConfig:
  definitions:
    generate: "generator.yaml"
  kafka:
    application.id: "example.datagen"
    bootstrap.servers: "broker:9092"
    security.protocol: PLAINTEXT


ksmlDefinitions:
  generator.yaml: |
    # This example shows how to generate data and have it sent to a target topic in a given format.

    functions:
      generate_sensordata_message:
        type: generator
        globalCode: |
          import time
          import random
          sensorCounter = 0
        code: |
          global sensorCounter

          key = "sensor"+str(sensorCounter)           # Set the key to return ("sensor0" to "sensor9")
          sensorCounter = (sensorCounter+1) % 10      # Increase the counter for next iteration

          # Generate some random sensor measurement data
          types = { 0: { "type": "AREA", "unit": random.choice([ "m2", "ft2" ]), "value": str(random.randrange(1000)) },
                    1: { "type": "HUMIDITY", "unit": random.choice([ "g/m3", "%" ]), "value": str(random.randrange(100)) },
                    2: { "type": "LENGTH", "unit": random.choice([ "m", "ft" ]), "value": str(random.randrange(1000)) },
                    3: { "type": "STATE", "unit": "state", "value": random.choice([ "off", "on" ]) },
                    4: { "type": "TEMPERATURE", "unit": random.choice([ "C", "F" ]), "value": str(random.randrange(-100, 100)) }
                  }

          # Build the result value using any of the above measurement types
          value = { "name": key, "timestamp": str(round(time.time()*1000)), **random.choice(types) }
          value["color"] = random.choice([ "black", "blue", "red", "yellow", "white" ])
          value["owner"] = random.choice([ "Alice", "Bob", "Charlie", "Dave", "Evan" ])
          value["city"] = random.choice([ "Amsterdam", "Xanten", "Utrecht", "Alkmaar", "Leiden" ])

          if random.randrange(10) == 0:
            value = None
        expression: (key, value)                      # Return a message tuple with the key and value
        resultType: (string, json)                    # Indicate the type of key and value

    producers:
      sensordata_json_producer:
        generator: generate_sensordata_message
        interval: 444
        to:
          topic: ksml_sensordata_json
          keyType: string
          valueType: json

applicationServer:
  enabled: true
  port: "8080"

prometheus:
  enabled: true
  port: "9993"
  config:
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    rules:
      - pattern: 'ksml<type=app-info, app-id=(.+), app-name=(.+), app-version=(.+), build-time=(.+)>Value:'
        name: ksml_app_info
        labels:
          app_id: "$1"
          name: "$2"
          version: "$3"
          build_time: "$4"
        type: GAUGE
        value: 1
        cached: true
      - pattern: .*

logging:
  configFile: '/ksml-logging/logback.xml'
  jsonEnabled: false
  patterns:
    stdout: '%date{"yyyy-MM-dd''T''HH:mm:ss,SSSXXX", UTC} %-5level %logger{36} - %msg%n'
    stderr: '%date{"yyyy-MM-dd''T''HH:mm:ss,SSSXXX", UTC} %-5level %logger{36} - %msg%n'
  loggers:
    org.apache.kafka: INFO
    org.apache.kafka.streams.StreamsConfig: INFO
    org.apache.kafka.clients.consumer.ConsumerConfig: INFO
```

</details>
